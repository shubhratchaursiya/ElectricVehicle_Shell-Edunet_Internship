# EV Charging Stations 2024 — Analysis & ML
# Author: Shubhrat Chaursiya
# Dataset: https://www.kaggle.com/datasets/sahirmaharajj/electric-vehicle-charging-stations-2024
# -----------------------------------------------------------------------------

import os
import re
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.cluster import KMeans
from sklearn.neighbors import KDTree

import folium
from folium.plugins import MarkerCluster

# ---------------- 0. Config ----------------
CSV_FILE = "electric_vehicle_charging_stations_2024.csv"  # <-- set to your downloaded file name
N_CLUSTERS = 30   # tune based on data size/coverage
MAP_SAMPLE = 5000 # limit points on map for performance (set None for all)

# ---------------- 1. Helpers ----------------
def _normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [re.sub(r"\s+", "_", c.strip().lower()) for c in df.columns]
    return df

def _pick_first_existing(df: pd.DataFrame, candidates):
    for c in candidates:
        if c in df.columns:
            return c
    return None

def _require(col, name_for_msg):
    if col is None:
        raise KeyError(f"Required column for '{name_for_msg}' not found. "
                       f"Open the CSV and check column names, then edit candidates list.")

# ---------------- 2. Load Dataset ----------------
if not os.path.exists(CSV_FILE):
    raise FileNotFoundError(
        f"CSV file '{CSV_FILE}' not found. Place the Kaggle CSV in this folder "
        f"or update CSV_FILE at the top of this script."
    )

df_raw = pd.read_csv(CSV_FILE, low_memory=False)
df = _normalize_columns(df_raw)

print("Columns detected:", list(df.columns)[:25], ("..." if df.shape[1] > 25 else ""))

# Try to locate standard fields with flexible fallbacks
lat_col = _pick_first_existing(df, ["latitude", "lat"])
lon_col = _pick_first_existing(df, ["longitude", "lon", "lng"])
name_col = _pick_first_existing(df, ["station_name", "name", "location_name", "site_name"])
city_col = _pick_first_existing(df, ["city", "town"])
state_col = _pick_first_existing(df, ["state", "state_province", "province", "region"])
country_col = _pick_first_existing(df, ["country"])
power_col = _pick_first_existing(df, ["power_kw", "kw", "max_power_kw", "rated_power_kw"])
status_col = _pick_first_existing(df, ["status", "operational_status", "availability"])
connectors_col = _pick_first_existing(df, ["connectors", "connector_types", "plug_types"])

# Require only lat/lon; others are optional but used if present
_require(lat_col, "latitude")
_require(lon_col, "longitude")

# ---------------- 3. Basic Info ----------------
print("\nShape:", df.shape)
print("\nMissing values (first 20 cols):\n", df.isna().sum().head(20))

# ---------------- 4. Cleaning ----------------
# keep essential columns + useful metadata if present
keep_cols = [c for c in [name_col, city_col, state_col, country_col,
                         connectors_col, power_col, status_col, lat_col, lon_col] if c]
df = df[keep_cols].copy()

# drop rows with invalid coordinates
df = df.dropna(subset=[lat_col, lon_col])
df = df[(df[lat_col].between(-90, 90)) & (df[lon_col].between(-180, 180))]

# remove exact duplicate stations by coordinates+name (if name exists)
if name_col:
    df = df.drop_duplicates(subset=[name_col, lat_col, lon_col])
else:
    df = df.drop_duplicates(subset=[lat_col, lon_col])

print("\nAfter cleaning, shape:", df.shape)

# ---------------- 5. Quick EDA ----------------
def safe_value_counts(col_name, topn=10):
    if col_name and col_name in df.columns:
        return df[col_name].value_counts().head(topn)
    return pd.Series(dtype="int64")

print("\nTop Countries:\n", safe_value_counts(country_col))
print("\nTop States/Provinces:\n", safe_value_counts(state_col))
print("\nTop Cities:\n", safe_value_counts(city_col))

# Histograms (guard for missing columns)
plt.figure(figsize=(7,4))
plt.hist(df[lat_col], bins=50)
plt.title("Latitude distribution")
plt.xlabel("Latitude"); plt.ylabel("Count"); plt.tight_layout(); plt.show()

plt.figure(figsize=(7,4))
plt.hist(df[lon_col], bins=50)
plt.title("Longitude distribution")
plt.xlabel("Longitude"); plt.ylabel("Count"); plt.tight_layout(); plt.show()

if power_col and power_col in df.columns:
    plt.figure(figsize=(7,4))
    plt.hist(df[power_col].dropna(), bins=40)
    plt.title("Installed Power (kW) Distribution")
    plt.xlabel("kW"); plt.ylabel("Count"); plt.tight_layout(); plt.show()

if connectors_col and connectors_col in df.columns:
    # crude parsing: split by comma/semicolon/pipe
    connectors_expanded = (df[connectors_col]
                           .dropna()
                           .astype(str)
                           .str.upper()
                           .str.replace(r"[;\|]", ",", regex=True)
                           .str.split(","))
    flat = pd.Series([i.strip() for sub in connectors_expanded for i in sub if i.strip()])
    print("\nTop Connector Types:\n", flat.value_counts().head(12))

# ---------------- 6. K-Means Clustering (site planning) ----------------
coords = df[[lat_col, lon_col]].to_numpy()
if len(coords) < N_CLUSTERS:
    N_CLUSTERS = max(1, len(coords) // 10) or 1
    print(f"\nAdjusted N_CLUSTERS to {N_CLUSTERS} due to small dataset.")

kmeans = KMeans(n_clusters=N_CLUSTERS, n_init="auto", random_state=42)
clusters = kmeans.fit_predict(coords)
df["cluster_id"] = clusters
centers = kmeans.cluster_centers_  # lat, lon order matches input
print(f"\nK-Means trained with {N_CLUSTERS} clusters.")

# Show cluster sizes
print("\nCluster sizes:\n", df["cluster_id"].value_counts().sort_index())

# ---------------- 7. KDTree for Nearest-Station Search ----------------
tree = KDTree(np.radians(coords))  # haversine-like approach if using radians + metric; here we use simple approx
def find_nearest_station(latitude, longitude, k=1):
    """Return nearest k station rows to the given coordinate."""
    # Use simple Euclidean in radians as fast proxy; adequate for small distances
    dist, idx = tree.query(np.radians([[latitude, longitude]]), k=k)
    return df.iloc[idx[0]].assign(approx_rad_distance=dist[0])

# Example (commented):
# print(find_nearest_station(28.6139, 77.2090, k=3))  # New Delhi approx

# ---------------- 8. Interactive Map ----------------
def make_map(sample=None, zoom_start=4):
    # center map at median coordinate
    lat_c, lon_c = float(np.median(df[lat_col])), float(np.median(df[lon_col]))
    m = folium.Map(location=[lat_c, lon_c], zoom_start=zoom_start, tiles="OpenStreetMap")

    points = df
    if sample is not None and len(df) > sample:
        points = df.sample(sample, random_state=42)

    cluster_layer = MarkerCluster(name="Charging Stations").add_to(m)
    for _, row in points.iterrows():
        popup_fields = []
        if name_col and pd.notna(row.get(name_col)):
            popup_fields.append(f"<b>{row[name_col]}</b>")
        if city_col and pd.notna(row.get(city_col)):
            popup_fields.append(f"City: {row[city_col]}")
        if state_col and pd.notna(row.get(state_col)):
            popup_fields.append(f"State: {row[state_col]}")
        if country_col and pd.notna(row.get(country_col])):
            popup_fields.append(f"Country: {row[country_col]}")
        if power_col and pd.notna(row.get(power_col)):
            popup_fields.append(f"Power (kW): {row[power_col]}")
        if status_col and pd.notna(row.get(status_col])):
            popup_fields.append(f"Status: {row[status_col]}")
        if connectors_col and pd.notna(row.get(connectors_col)):
            popup_fields.append(f"Connectors: {row[connectors_col]}")

        popup_html = "<br>".join(popup_fields) if popup_fields else "Charging Station"
        folium.CircleMarker(
            location=[row[lat_col], row[lon_col]],
            radius=3,
            fill=True,
            fill_opacity=0.7,
            popup=folium.Popup(popup_html, max_width=450),
        ).add_to(cluster_layer)

    # Add cluster centers
    center_group = folium.FeatureGroup(name="Cluster Centers").add_to(m)
    for i, (clat, clon) in enumerate(centers):
        folium.Marker(
            [clat, clon],
            icon=folium.Icon(icon="flag"),
            tooltip=f"Cluster {i}",
            popup=f"Cluster {i} center"
        ).add_to(center_group)

    folium.LayerControl().add_to(m)
    return m

ev_map = make_map(sample=MAP_SAMPLE, zoom_start=4)
map_file = "ev_stations_clusters_map.html"
ev_map.save(map_file)
print(f"\nInteractive map saved to: {map_file}")

# ---------------- 9. Outputs / Artifacts ----------------
# Save clustered dataset
out_csv = "ev_stations_with_clusters.csv"
df.to_csv(out_csv, index=False)
print(f"Clustered dataset saved to: {out_csv}")

print("\n✅ Done. You can:")
print(" - Open the HTML map to explore stations and cluster centers")
print(" - Use find_nearest_station(lat, lon, k) in a Python shell for nearest lookup")
print(" - Tune N_CLUSTERS and re-run to try different site-planning granularities")
